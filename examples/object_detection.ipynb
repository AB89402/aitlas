{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of the `aitlas` toolbox in the context of object detection\n",
    "\n",
    "## This notebook shows a sample implementation of object detection using the `aitlas` toolbox on the DOTAv1.0 (Task 2) dataset.\n",
    "\n",
    "### Before using the object detection code provided in `aitlas` on the DOTAv1.0 dataset, it is important to split the images in the train/validation/test subsets into patches using the code available in this [Development kit](https://github.com/CAPTAIN-WHU/DOTA_devkit).\n",
    "\n",
    "### The structure of the directories which hold the split images should be the following:\n",
    "```\n",
    "trainsplit/valsplit/testsplit\n",
    "└───images\n",
    "│   │   file011.png\n",
    "│   │   file012.png\n",
    "│   │   ...\n",
    "│   \n",
    "└───labelTxt\n",
    "    │   file011.txt\n",
    "    │   file012.txt\n",
    "    │   ...\n",
    "```\n",
    "\n",
    "### A link to the DOTA project: [https://captain-whu.github.io/DOTA/dataset.html](https://captain-whu.github.io/DOTA/dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "from aitlas.datasets.esri_challenge import EsriChallengeDataset\n",
    "from aitlas.datasets.dota import DotaDataset\n",
    "\n",
    "# models\n",
    "from aitlas.models.fastrcnn_detector import FastRCNN\n",
    "from aitlas.models.retinanet import RetinaNet\n",
    "\n",
    "# vizualization\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define configurations for all subsets of the dataset\n",
    "\n",
    "### Configuration parameters:\n",
    "```\n",
    "- root (str): The path where the train/val/test splits can be found\n",
    "- subset (str): The name of the folder inside the root directory which contains the images and labels of the split\n",
    "- subsample_percentage (float): A percentage of the subset images which sould be used\n",
    "- batch_size (int): Pytorch batch_size parameter\n",
    "- shuffle (bool): Pytorch dataloader shuffle parameter\n",
    "- num_workers (int): Pytorch dataloader num_workers parameter\n",
    "- filter_null (bool): Whether to remove the images(patches) without any bounding boxes\n",
    "- transforms (list): A list of transformation functions to be applied to the images in the subset\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\\\Documents\\\\AiTLAS\\\\aitlas\\\\ESRI-challenge\\\\data\\\\DOTA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = {\n",
    "    \"root\": data_path,\n",
    "    \"subset\": \"validationsplit\",\n",
    "    \"subsample_percentage\": 0.3,\n",
    "    \"batch_size\": 2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0,\n",
    "    \"filter_null\": True,\n",
    "    \"transforms\": [\"torchvision.transforms.ToTensor\"]\n",
    "}\n",
    "train_set = DotaDataset(train_cfg)\n",
    "\n",
    "val_cfg = {\n",
    "    \"root\": data_path,\n",
    "    \"subset\": \"validationsplit\",\n",
    "    \"subsample_percentage\": 0.3,\n",
    "    \"batch_size\": 2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0,\n",
    "    \"filter_null\": True, \n",
    "    \"transforms\": [\"torchvision.transforms.ToTensor\"]\n",
    "}\n",
    "val_set = DotaDataset(val_cfg)\n",
    "\n",
    "test_cfg = {\n",
    "    \"root\": data_path,\n",
    "    \"subset\": \"testsplit\",\n",
    "    # this parameter does not matter when `test` is in the name of the subset\n",
    "    \"subsample_percentage\": 1.0,\n",
    "    \"batch_size\": 2,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0,\n",
    "    # this parameter does not matter when `test` is in the name of the subset\n",
    "    \"filter_null\": True, \n",
    "    \"transforms\": [\"torchvision.transforms.ToTensor\"]\n",
    "}\n",
    "test_set = DotaDataset(test_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 40 examples from the training subset along with their annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 40\n",
    "num_images = train_set.__len__()\n",
    "\n",
    "example_ind = np.random.randint(0, num_images, size = num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 8, figsize = (22, 15))\n",
    "\n",
    "for (example_idx, ax) in zip(example_ind, axes.flatten()):\n",
    "    image, labels = train_set.__getitem__(example_idx)\n",
    "    img = image.cpu().numpy().copy()\n",
    "    img = np.rollaxis(img, 0, 3)\n",
    "    img = (img*255).astype(np.uint16)\n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for (box, label) in zip(labels['boxes'].cpu().numpy().astype(np.int32), labels['labels'].cpu().numpy()):        \n",
    "        tab20 = mpl.cm.get_cmap('tab20', 20)\n",
    "        ax.add_patch(patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1], edgecolor=tab20(label), linewidth = 2, facecolor='none'))\n",
    "        ax.add_patch(patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1], edgecolor=tab20(label), facecolor=tab20(label), alpha=0.3))\n",
    "        ax.axis('off')\n",
    "\n",
    "    \n",
    "    tab20 = mpl.cm.get_cmap('tab20', 20)\n",
    "    legend_items = []\n",
    "    for cat, value in train_set.mappings.items():\n",
    "        legend_items.append(patches.Patch(color=tab20(value), label=cat))\n",
    "    plt.legend(loc = 'upper left', bbox_to_anchor=(1.05, 4.), handles = legend_items)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RetinaNet as the model to use for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOTA v1.0 has 15 unique classes + a background class\n",
    "num_classes = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\"num_classes\": num_classes, \"learning_rate\": 0.001, \"pretrained\": True}\n",
    "\n",
    "model = RetinaNet(model_cfg)\n",
    "\n",
    "model.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Train a RetinaNet model on the training subset and evaluate it after every epoch using the validation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_and_evaluate_model(\n",
    "    train_dataset=train_set,\n",
    "    val_dataset=val_set,\n",
    "    epochs=num_epochs,\n",
    "    model_directory = \"./retinanet_dota/\",\n",
    "    run_id = \"{}-retinanet\".format(\"DOTA\"),\n",
    "    iterations_log = log_interval,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and save the predictions on disk\n",
    "\n",
    "### The output directory must exist on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_output_path = \"./task2_val_predictions\"\n",
    "test_output_path = \"./task2_test_predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict_with_output(val_set, description = 'Predicting the validation set')\n",
    "val_set.add_predictions(val_predictions)\n",
    "val_set.save_predictions(val_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict_with_output(test_set, description = 'Predicting the test set')\n",
    "test_set.add_predictions(test_predictions)\n",
    "test_set.save_predictions(test_output_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74e46c725584c0a0efe812c12512a417aaf5813940beb14617dfd18831f9d066"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('aitlas': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
