import os
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch

from ..base import BaseDataset
from torch.utils.data import DataLoader, Dataset
from ..utils import tiff_loader
from skimage.transform import resize
from .semantic_segmentation import SemanticSegmentationDataset
from ..utils import image_loader
from .schemas import CloudDatasets_AI4QCSchema


def interp_band(bands, img_shape=[256, 256]):
    
    bands_interp = np.zeros(img_shape).astype(np.float32)
    bands_interp = resize(bands/10000, img_shape, mode="reflect")*10000 #10000 because of the reflectance mode (initial values are DN)

    return bands_interp

'''
Set of reference cloud mask data generated by an active learning method for 30 Sentinel-2 scenes over 10 sites: 
Alta Floresta (Brazil), Arles (France), Ispra (Italy), Munich (Germany), Orleans (France), Gobabeb (Namibia), Marrakech (Morocco), 
Railroad Valley (USA), Pretoria (South AFrica) and Mongu (Zambia). The scenes are collected for different seasons and cloud cover 
types. The dataset is a smaller version of the CESBIO dataset, where the S2 L1C images have been added and the classes modified.
'''
    
class CESBIO_AI4QCDataset(SemanticSegmentationDataset):

    url = "https://zenodo.org/records/11120395"

    labels = ["clear","thick cloud","thin cloud","cloud shadow"]
    color_mapping = [[255,255,255],[0,0,255],[0,255,255],[128,128,128]]
    name = "CESBIO_AI4QC"
    schema = CloudDatasets_AI4QCSchema
    
    def __init__(self, config):
        # now call the constructor to validate the schema and split the data
        super().__init__(config)
        self.data_dir = self.config.data_dir
        self.selection = self.config.selection

    def __getitem__(self, index):
        mask = image_loader(self.masks[index],False)
        masks = [(mask == v) for v, label in enumerate(self.labels)]
        mask = np.stack(masks, axis=-1).astype("float32")
        
        if self.selection == "rgb":
            image = image_loader(self.images[index])
            if self.transform:
                image = self.transform(image)
            if self.target_transform:
                mask = self.target_transform(mask)
            return image, mask

        elif self.selection == "all":
            imageB01 = image_loader(self.imagesB01[index])
            imageB01 = interp_band(imageB01)
            imageB02 = image_loader(self.imagesB02[index])
            imageB02 = interp_band(imageB02)
            imageB03 = image_loader(self.imagesB03[index])
            imageB03 = interp_band(imageB03)
            imageB04 = image_loader(self.imagesB04[index])
            imageB04 = interp_band(imageB04)
            imageB05 = image_loader(self.imagesB05[index])
            imageB05 = interp_band(imageB05)
            imageB06 = image_loader(self.imagesB06[index])
            imageB06 = interp_band(imageB06)
            imageB07 = image_loader(self.imagesB07[index])
            imageB07 = interp_band(imageB07)
            imageB08 = image_loader(self.imagesB08[index])
            imageB08 = interp_band(imageB08)
            imageB8A = image_loader(self.imagesB8A[index])
            imageB8A = interp_band(imageB8A)
            imageB09 = image_loader(self.imagesB09[index])
            imageB09 = interp_band(imageB09)
            imageB10 = image_loader(self.imagesB10[index])
            imageB10 = interp_band(imageB10)
            imageB11 = image_loader(self.imagesB11[index])
            imageB11 = interp_band(imageB11)
            imageB12 = image_loader(self.imagesB12[index])
            imageB12 = interp_band(imageB12)
            
            image = np.dstack((imageB01,imageB02,imageB03,imageB04, imageB05,imageB06,imageB07,imageB08,imageB8A,imageB09,imageB10,imageB11,imageB12))
            image = image.astype(np.float32)
            
            #transpose and normalize between 0 and 1
            image = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32) / 10000

            if self.transform:
                image = self.transform(image)
            if self.target_transform:
               mask = self.target_transform(mask)

            return image, mask

    def load_dataset(self, data_dir, csv_file=None):
        if not self.labels:
            raise ValueError("You need to provide the list of labels for the dataset")

        ids = os.listdir(os.path.join(data_dir, "S2_images"))
        self.images = [os.path.join(data_dir, "S2_images", image_id) for image_id in ids]
        self.imagesB01 = [os.path.join(data_dir, "B01", image_id[: image_id.rfind('.tif')]+'_B01.tif') for image_id in ids]
        self.imagesB02 = [os.path.join(data_dir, "B02", image_id[: image_id.rfind('.tif')]+'_B02.tif') for image_id in ids]
        self.imagesB03 = [os.path.join(data_dir, "B03", image_id[: image_id.rfind('.tif')]+'_B03.tif') for image_id in ids]
        self.imagesB04 = [os.path.join(data_dir, "B04", image_id[: image_id.rfind('.tif')]+'_B04.tif') for image_id in ids]
        self.imagesB05 = [os.path.join(data_dir, "B05", image_id[: image_id.rfind('.tif')]+'_B05.tif') for image_id in ids]
        self.imagesB06 = [os.path.join(data_dir, "B06", image_id[: image_id.rfind('.tif')]+'_B06.tif') for image_id in ids]
        self.imagesB07 = [os.path.join(data_dir, "B07", image_id[: image_id.rfind('.tif')]+'_B07.tif') for image_id in ids]
        self.imagesB08 = [os.path.join(data_dir, "B08", image_id[: image_id.rfind('.tif')]+'_B08.tif') for image_id in ids]
        self.imagesB8A = [os.path.join(data_dir, "B8A", image_id[: image_id.rfind('.tif')]+'_B8A.tif') for image_id in ids]
        self.imagesB09 = [os.path.join(data_dir, "B09", image_id[: image_id.rfind('.tif')]+'_B09.tif') for image_id in ids]
        self.imagesB10 = [os.path.join(data_dir, "B10", image_id[: image_id.rfind('.tif')]+'_B10.tif') for image_id in ids]
        self.imagesB11 = [os.path.join(data_dir, "B11", image_id[: image_id.rfind('.tif')]+'_B11.tif') for image_id in ids]
        self.imagesB12 = [os.path.join(data_dir, "B12", image_id[: image_id.rfind('.tif')]+'_B12.tif') for image_id in ids]
        self.masks = [os.path.join(data_dir, "classification_maps", 'mask_' + image_id) for image_id in ids]

    def data_distribution_table(self):
        label_dist = {key: 0 for key in self.labels}
        for image, mask in self.dataloader():
            for index, label in enumerate(self.labels):
                label_dist[self.labels[index]] += mask[:, :, :, index].sum()
        label_count = pd.DataFrame.from_dict(label_dist, orient='index')
        label_count.columns = ["Number of pixels"]
        label_count = label_count.astype(float)
        return label_count
