{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "from aitlas.datasets.esri_challenge import EsriChallengeDataset\n",
    "from aitlas.datasets.dota import DotaDataset\n",
    "\n",
    "# models\n",
    "from aitlas.models.fastrcnn_detector import FastRCNN\n",
    "from aitlas.models.retinanet import RetinaNet\n",
    "\n",
    "# vizualization\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define either of the two datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESRI challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images on disk is: 3228\n",
      "The subsampled number of images is: 64\n",
      "The number of images on disk is: 520\n",
      "The subsampled number of images is: 10\n"
     ]
    }
   ],
   "source": [
    "train_cfg = {\n",
    "    \"root\": \"E:\\\\AiTLAS\\\\aitlas\\\\ESRI-challenge\\\\data\\\\ESRI\",\n",
    "    \"subset\": \"train\",\n",
    "    \"subsample_percentage\": 0.02,\n",
    "    \"batch_size\": 4,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 4,\n",
    "    \"transforms\": [\"torchvision.transforms.ToTensor\"]\n",
    "}\n",
    "train_set = EsriChallengeDataset(train_cfg)\n",
    "\n",
    "test_cfg = {\n",
    "    \"root\": \"E:\\\\AiTLAS\\\\aitlas\\\\ESRI-challenge\\\\data\\\\ESRI\",\n",
    "    \"subset\": \"test\",\n",
    "    \"subsample_percentage\": 0.02,\n",
    "    \"batch_size\": 4,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 4,\n",
    "    \"transforms\": [\"torchvision.transforms.ToTensor\"]\n",
    "}\n",
    "test_set = EsriChallengeDataset(test_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cfg = {\n",
    "#     \"root\": \"D:\\\\Documents\\\\AiTLAS\\\\aitlas\\\\ESRI-challenge\\\\data\\\\DOTA\",\n",
    "#     \"subset\": \"validation_split\",\n",
    "#     \"subsample_percentage\": 0.01,\n",
    "#     \"batch_size\": 2,\n",
    "#     \"shuffle\": True,\n",
    "#     \"num_workers\": 0,\n",
    "#     \"filter_null\": True,\n",
    "#     \"transforms\": [\"torchvision.transforms.ToTensor\"]\n",
    "# }\n",
    "# train_set = DotaDataset(train_cfg)\n",
    "\n",
    "# test_cfg = {\n",
    "#     \"root\": \"D:\\\\Documents\\\\AiTLAS\\\\aitlas\\\\ESRI-challenge\\\\data\\\\DOTA\",\n",
    "#     \"subset\": \"validation_split\",\n",
    "#     \"subsample_percentage\": 0.01,\n",
    "#     \"batch_size\": 2,\n",
    "#     \"shuffle\": True,\n",
    "#     \"num_workers\": 0,\n",
    "#     \"filter_null\": True, \n",
    "#     \"transforms\": [\"torchvision.transforms.ToTensor\"]\n",
    "# }\n",
    "# test_set = DotaDataset(train_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot examples of dataset annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_examples = 40\n",
    "# num_images = train_set.__len__()\n",
    "\n",
    "# example_ind = np.random.randint(0, num_images, size = num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 5, ncols = 8, figsize = (22, 15))\n",
    "\n",
    "# for (example_idx, ax) in zip(example_ind, axes.flatten()):\n",
    "#     image, labels = train_set.__getitem__(example_idx)\n",
    "#     img = image.cpu().numpy().copy()\n",
    "#     img = np.rollaxis(img, 0, 3)\n",
    "#     img = (img*255).astype(np.uint16)\n",
    "\n",
    "#     ax.imshow(img)\n",
    "\n",
    "#     for (box, label) in zip(labels['boxes'].cpu().numpy().astype(np.int32), labels['labels'].cpu().numpy()):        \n",
    "#         tab20 = mpl.cm.get_cmap('tab20', 20)\n",
    "#         ax.add_patch(patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1], edgecolor=tab20(label), linewidth = 2, facecolor='none'))\n",
    "#         ax.add_patch(patches.Rectangle((box[0],box[1]),box[2]-box[0],box[3]-box[1], edgecolor=tab20(label), facecolor=tab20(label), alpha=0.3))\n",
    "#         ax.axis('off')\n",
    "\n",
    "    \n",
    "#     tab20 = mpl.cm.get_cmap('tab20', 20)\n",
    "#     legend_items = []\n",
    "#     for cat, value in train_set.mappings.items():\n",
    "#         legend_items.append(patches.Patch(color=tab20(value), label=cat))\n",
    "#     plt.legend(loc = 'upper left', bbox_to_anchor=(1.05, 4.), handles = legend_items)\n",
    "        \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model getter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fastrcnn(num_classes = 3):\n",
    "    model_cfg = {\"num_classes\": num_classes, \"learning_rate\": 0.001, \"pretrained\": True}\n",
    "\n",
    "    # load a model pre-trained on COCO\n",
    "    model = FastRCNN(model_cfg)\n",
    "\n",
    "    model.prepare()\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_retinanet(num_classes = 3):\n",
    "    model_cfg = {\"num_classes\": num_classes, \"learning_rate\": 0.001, \"pretrained\": True}\n",
    "    \n",
    "    model = RetinaNet(model_cfg)\n",
    "\n",
    "    model.prepare()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the performance of FastRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-14 14:01:49,370 INFO Starting training.\n",
      "training:  56%|█████▋    | 9/16 [00:11<00:06,  1.02it/s]2021-10-14 14:02:03,350 INFO [1, 10], loss:  3.19690\n",
      "training: 100%|██████████| 16/16 [00:16<00:00,  1.04s/it]\n",
      "2021-10-14 14:02:07,729 INFO epoch: 1, time: 16, loss:  0.67264\n",
      "testing on train set: 100%|██████████| 16/16 [00:17<00:00,  1.08s/it]\n",
      "2021-10-14 14:02:28,740 INFO mAP mean:tensor(0.0377), AP per Class:tensor(0.0433), tensor(0.0322)\n",
      "testing on validation set: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]\n",
      "2021-10-14 14:02:35,540 INFO mAP mean:tensor(0.2328), AP per Class:tensor(0.0713), tensor(0.3942)\n",
      "training:  56%|█████▋    | 9/16 [00:09<00:05,  1.18it/s]2021-10-14 14:02:45,516 INFO [2, 10], loss:  1.65462\n",
      "training: 100%|██████████| 16/16 [00:14<00:00,  1.12it/s]\n",
      "2021-10-14 14:02:49,884 INFO epoch: 2, time: 14, loss:  0.38101\n",
      "testing on train set: 100%|██████████| 16/16 [00:17<00:00,  1.12s/it]\n",
      "2021-10-14 14:03:07,854 INFO mAP mean:tensor(0.0632), AP per Class:tensor(0.0593), tensor(0.0671)\n",
      "testing on validation set: 100%|██████████| 3/3 [00:06<00:00,  2.23s/it]\n",
      "2021-10-14 14:03:14,562 INFO mAP mean:tensor(0.3396), AP per Class:tensor(0.6559), tensor(0.0233)\n",
      "training:  56%|█████▋    | 9/16 [00:09<00:05,  1.18it/s]2021-10-14 14:03:24,516 INFO [3, 10], loss:  1.46314\n",
      "training: 100%|██████████| 16/16 [00:14<00:00,  1.12it/s]\n",
      "2021-10-14 14:03:28,904 INFO epoch: 3, time: 14, loss:  0.34733\n",
      "testing on train set: 100%|██████████| 16/16 [00:13<00:00,  1.23it/s]\n",
      "2021-10-14 14:03:41,970 INFO mAP mean:tensor(0.1162), AP per Class:tensor(0.0891), tensor(0.1432)\n",
      "testing on validation set: 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]\n",
      "2021-10-14 14:03:48,191 INFO mAP mean:tensor(0.3180), AP per Class:tensor(0.1952), tensor(0.4409)\n",
      "2021-10-14 14:03:52,306 INFO finished training. training time: 123\n"
     ]
    }
   ],
   "source": [
    "# get the model using our helper function\n",
    "model = get_fastrcnn(num_classes = 3)\n",
    "\n",
    "model.train_and_evaluate_model(\n",
    "    train_dataset=train_set,\n",
    "    val_dataset=test_set,\n",
    "    epochs=3,\n",
    "    model_directory = \"./experiment/\",\n",
    "    run_id = \"esri-fastrcnn\",\n",
    "    iterations_log = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Test the performance of RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model using our helper function\n",
    "model = get_retinanet(num_classes = 3)\n",
    "\n",
    "model.train_and_evaluate_model(\n",
    "    train_dataset=train_set,\n",
    "    val_dataset=test_set,\n",
    "    epochs=20,\n",
    "    model_directory = \"./experiment/\",\n",
    "    run_id = \"esri-retinanet\",\n",
    "    iterations_log = 40\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74e46c725584c0a0efe812c12512a417aaf5813940beb14617dfd18831f9d066"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('aitlas': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
